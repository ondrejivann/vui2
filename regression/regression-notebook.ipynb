{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stažení a instalace knihoven, které budeme používat\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install scipy\n",
    "!{sys.executable} -m pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import knihoven, které budeme používat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Regrese\n",
    "\n",
    "#### Autoři:\n",
    "* [Martin Vlach](mailto:xvlach@mendelu.cz)\n",
    "* [Jakub Dolejší](mailto:xdolejsi@mendelu.cz)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regrese v různých vědních odvětvích\n",
    "- **Lékařství** - *regrese nemoci*\n",
    "- **Právo** - *regresy*\n",
    "- **Filozofie** - *nekonečný regres*\n",
    "- **Softwarové inženýrství** - *regresní testování*\n",
    "- <span style=\"color:#eb4034\">**Statistika** - *regresivní analýza*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Regresivní analýza\n",
    "* Jedna z nejpoužívanějších statistických metod.\n",
    "* Existuje značné množství variant, přičemž každá je vhodná na jiný typ problému.\n",
    "\n",
    "</br>\n",
    "\n",
    "* ***Definice*** - *Označení statistických metod, které souží k odhadu jisté náhodné veličiny na základě znalosti jedné či více jiných veličin. Cílem regresní analýzy je popsat tuto závislost pomocí vhodného modelu.*\n",
    "\n",
    "    * ***Závislá proměnná*** - *Parametr, jehož hodnotu zkoumáme/hledáme.*\n",
    "    * ***Nezávislá proměnná*** - *Parametr, jehož hodnota je nám známa. S využítím těchto hodnot je hledána hodnota závislé proměnné. Tyto hodnoty se často označují jako regresory*\n",
    "\n",
    "#### Velmi důležitá jsou data (dataset)\n",
    "* Dostatečně velký\n",
    "* Reprezentativní\n",
    "* Získán konzistentní metodologií se signifikantní přesností\n",
    "* Nezávislý\n",
    "\n",
    "\n",
    "\n",
    "### Co to regrese vůbec je?\n",
    "Regrese je obecně aparát sloužící k odhadu vztahu mezi závislou a nezávislou proměnnou.\n",
    "Regresi si lze představit jak funkci, která má obecně N vstupů a jeden výstup. Každý jeden vstupní\n",
    "parametr představuej nezávislou proměnnou, přičemž výstup je proměnná závislá na všech vstupech.\n",
    "\n",
    "\n",
    "<img src=\"images/regression.jpg\" alt=\"drawing\" width=\"350\"/>\n",
    "\n",
    "### Jaké jsou její typy\n",
    "\n",
    "\n",
    "\n",
    "Jak již bylo zmíněno, regresi lze rozdělit do několika tříd dle jejího využití. Regrese je jedním\n",
    " ze základních metod <i>učení s učitelem</i>. Pravděpodobně nejčastěji použitým typem regrese je lineární regrese. Jejím zobecněním následně je vícenásobná lineární\n",
    "regrese. Pro určité typy vztahů je vhodné použít regresi polynomiální. Dále existuje logistická regrese, která slouží ke klasifikaci, tj. zařazení vstupní\n",
    "hodnoty do některé ze tříd s určitou pravděpodobností. Pokročilým typem regrese je\n",
    "<i>Support Vector Machine</i>, který slouží i k klasifikaci.\n",
    "\n",
    "#### Dělení regresivních modelů\n",
    "* Spojité hodnoty závislých proměnných **x** Diskrétní hodnoty závislých proměnných (klasifikační)\n",
    "* Jednoduchá **x** Vícenásobná\n",
    "* Lineární **x** Nelineární závislost\n",
    "* Parametrické **x** Neparametrické\n",
    "---\n",
    "\n",
    "#### Lineární regrese\n",
    "Lineární regrese je, jak již bylo avizovno, speciálním případem obecného regresního modelu.\n",
    "Lineární regrese ma na svém vstupu nezávislou proměnnou, např. plocha pozemku, a na svém\n",
    "výstupu závislou proměnnou, např. cena. Cílem lineární regrese ja najít takovou lineární funkci,\n",
    "která bude co nejlépe aproximovat daný soubor dat. Obecným předpokladem pro lineární regrese\n",
    "je že data mají lineární trend, tj. je možné je proložit lineární přímkou.\n",
    "\n",
    "Naším úkolem je naučit se lineární funkci tj. najít vhodné parametry $ w_{1} $ a $w_{0}$.\n",
    "\n",
    " $ y = f(x) = w_{1}x + w_{0} $\n",
    "\n",
    "Dále předpokládáme, že skutečné hodnoty z datasetu jsou zatíženy chybou.\n",
    "\n",
    "$ t = y_{n} + \\epsilon _{n}  $, kde $\\epsilon$ je Gaussovský šum\n",
    "\n",
    "To znamená, že hodnoty z našeho datasetu neleží přímo na lineární přímce, ale jsou rozptýleny kolem ní, a to\n",
    "dle normálního rozložení $ N(\\mu ; 0, \\sigma^2) $, přičemž střední hodnota je nulová a rozptyl se ja závislý\n",
    "na datasetu.\n",
    "\n",
    "\n",
    "![image info](images/error.png)\n",
    "\n",
    "Z obrázku vidíme, že každý vstup z datasetu je zatížen nějakou chybou (pokud by nebyl, všechny\n",
    "data by ležela na lineární přímce). Zde lze postupovat několika způsoby, nicméně v každém případě se budeme snažit nalézt parametry\n",
    "lineární přímky tak, aby výsledná chyba byla co nejmenší\n",
    "\n",
    "<ol>\n",
    "<li><b>Pomocí metody nejmenších čtverců</b></li>\n",
    " Nejdříve je nutné najít chybu, což lze udělat tak, že si vypočteme druhou mocninu všech chyb, tedy\n",
    " čtverce, a sečteme je.\n",
    "\n",
    " $ E(w_{0}, w_{1}) = \\sum \\limits _{i=1} ^N (t_{n} - y_{n})^2 = \\sum \\limits _{i=1} ^N (t_{n} - w_{1}x + w_{0})^2$\n",
    "\n",
    "Pro každý vzorek z datasetu vezmeme jeho skutečnou hodnotu, odečteme od něj predikovanou\n",
    "hodnotu, a získame chybu konkrétního vzorku, kterou následně umocníme na druhou.\n",
    "Tyto chyby sečteme a získáme celkovou chybu. Nyní je na místě si položit otázku, proč je nutné\n",
    "provést umocnění. Odpoveď je taková, že kdyby jeden vzorek obsahoval chybu +0.5 a druhý vzorek\n",
    "-0.5, tyto dvě hodnoty by se nám díky sumě odečetly, a celková chyba by byla 0, což ovšem není pravda,\n",
    "protože by hodnoty vzorů musely ležet přímo na přímce. Tam ale neleží, což víme díky tomu, že každý\n",
    "oba vzorky jsou zatíženy nějakou chybou.\n",
    "\n",
    "Jako další vhodná operace se nabízí absolutní hodnota. Ta nám již odstraní případné\n",
    "odečtení chyby, nicméně jak posléze zjistíme, bude potřeba provést parciální derivace. Derivace\n",
    "mocniny je ovšem daleko jednoduší než derivace absolutní hodnoty. Dále, kvadratická chyba nám zajistí,\n",
    "že se hodnoty datasetu budou chovat, jako by byly rozmístěny dle normálního rozložení\n",
    "se středem v predikované hodnotě lineární funkce, což je náš předpoklad. Konečně, kvadratická\n",
    "funkce má pouze jedno lokální, resp. globální minimum.\n",
    "\n",
    "(Poznámka: Pokud bychom chtěli použít absolutní hodnotu, pracovali bychom s Lappplaceovým rozložení)\n",
    "\n",
    "\n",
    "Jak již bylo naznačeno, naším úkolem je nalézt globální minimmum z funkce $E(w_{0}, w_{1})$, tj.\n",
    "nalézt takové parametry  $w_{0}, w_{1}$, pro které bude bude suma všech čtverců chyb nejmenší.\n",
    "Z matematické analýzy víme, že se pokud hledáme globální minimum, tak je nutné nalézt\n",
    "parciální derivace funkce pode $w_{0}$ a $w_{1}$ a následně sestavit soustavu dvou rovnic\n",
    "o dovu neznámých.\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{0}} = 0 $\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{1}} = 0 $\n",
    "\n",
    "Vypočteme derivaci podle $w_{0}$ a vypočteme; analogicky určítem i $w_{1}$ .\n",
    "\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{0}} = ...  -2 (\\sum_{i=0}^N t_{i} - w_{0}(n+1) - w_{1} \\sum_{i=0}^N x_{i})$\n",
    "\n",
    "$ \\frac {\\partial E}{\\partial w_{1}} = \\sum_{i=0}^N 2(t_{i} - w_{0} - w_{1}x_{i})(-x_{i}) = -2 \\sum_{i=0}^N (t_{i}x_{i} - w_{0}x_{i} - w_{1}x_{i}^2)  $\n",
    "\n",
    "Výsledky paricálních derivací nyní dosadit do soustavy rovnic, a máme výslednou,\n",
    "tzn. <b>normální rovnici</b>.\n",
    "\n",
    "$ w_{0}(n+1) + w_{1}\\sum_{i=0}^N x_{i} = \\sum_{i=0}^N t_{i} $\n",
    "\n",
    "$ w_{0} \\sum_{i=0}^N x_{i} + w_{1} \\sum_{i=0}^N x_{i}^2 = \\sum_{i=0}^N x_{i}t_{i}$\n",
    "\n",
    "<br/>\n",
    "<li><b>Pomocí gradientího sestupu</b></li>\n",
    "\n",
    "Častější je ovšem využití gradientu. Gradient je vektor, který nám ukazuje, jakým směrem je\n",
    "derivace největší, tj. jakým směrem přímka nejrychleji stoupá. Pokud tento vektor otočíme o 90 stupňů,\n",
    "bude ukazovat kudy naše funkce nejrychleji klesá, a to je přesně co chceme. Z úvodu víme, že\n",
    "budeme hledat minimum v kvadratické funkci, která má minimum pouze jedno. To znamená, že se\n",
    "nemusíme obávat, že by jsme uvázli v lokálním minimu.\n",
    "\n",
    "Jedím z algoritmů pro nalezení takovéhoto minima je <i>Steepest Gradient Descent</i>. Tento\n",
    "algoritmus postupuje po krocích zvolené délky, a pro každý krok počítá nový gradient, tj. nový směr,\n",
    "kterým má postupovat. A kdy že se má alogritmus zastavit? Opět víme, že pokud je derivace\n",
    "nulová, může to znamenat hned několik věcí. Může se zde nacházet bod podezřelý z extrému, inflexní bod\n",
    "či lokální minimum. V každém případě to ovšem znamená, že daná funkce je zde\n",
    "rovnoběžná s osou <i>x</i>, a to implikuje jediné; našli jsme minimum funkce.\n",
    "\n",
    "\n",
    "\n",
    "Nevýhodou tohoto algoritmu je skutečnost, že pro výpočet každého gradientu je nutné projít\n",
    "celý dataset. Pokud náš dataset obsahuje 100 milionů záznamů, může to být trošku problém. V tomto\n",
    "případě lze zvolit jinou metodu, kupříkladu <i>Stochastic Gradient Descent</i>. Tato metoda počítá\n",
    "gradient z jednoho, náhodně výbraného vzorku. Její postup samozřejmě není tolik přímočarý\n",
    "jako v případě  <i>Steepest Gradient Descent</i>, ovšem není tolik náročný.\n",
    "\n",
    "\n",
    "![SegmentLocal](images/gradient.gif \"segment\")\n",
    "\n",
    "<li><b>Analytické řešení</b></li>\n",
    "\n",
    "Posledním, ovšem nejvíce sofistikovaným způsobem je využít operací nad maticemi a vektory, pomocí\n",
    "kterých lze dojít k výsledku během jednoho kroku. To znamená, že nad naší vstupní rovnicí provedeme\n",
    "několik maticových operací, jejiž výsledkem budou optimální parametry $w_{0}$ a $w_{1}$.\n",
    "\n",
    "Nejdříve začneme tím, že si rovnici můžeme přepsat do skalárního součinu.\n",
    "\n",
    "$y = w_{1}x + w_{0} =  \\hat x^Tw $ , kde\n",
    "\n",
    "$ \\mathbf{\\hat x}= \\begin{bmatrix}1 \\\\\n",
    "x\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$ \\mathbf{w}= \\begin{bmatrix}w_{0} \\\\\n",
    "w_{1}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Můžeme něco takového udělat? Samozřejmě, protože násobíme transponovaný sloupcpvý vektor, tj. řádkový\n",
    "s sloupcovým vektorem. Tzn. máme operaci\n",
    "$\\begin{bmatrix}1 \\space\n",
    "x\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}w_{0} \\\\\n",
    "w_{1}\n",
    "\\end{bmatrix} = 1 w_{0} + xw_{1} = w_{1}x + w_{0} = y$\n",
    "\n",
    "\n",
    "Vzorec pro objektivní funkci je opět stejný, nicméně pro další odovozování použijeme\n",
    "notaci skalárního součinu a přidáme vynásobení konstantou. Tato konstanta nás nijak netrápí,\n",
    "na nalezení minima či maxima to nemá žádný vliv.\n",
    "\n",
    "$ E(w0, w1) = \\frac{1}{2} \\sum \\limits _{i=1} ^N (t_{n} - y_{n})^2 =\\frac{1}{2} \\sum \\limits _{i=1} ^N (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w} )^2$\n",
    "\n",
    "Nyní si naši funkci dvou proměnných $ E(w0, w1)$ můžeme přepsat jako funkci\n",
    " vektoru $ E( \\mathbf{w})$. Nebude nyní derivovat podle dvou proměnných, ale podle vektoru.\n",
    " Výstupem této funkce je opět nám již známý gradient.\n",
    "\n",
    "\n",
    "\n",
    " $ \\frac{\\partial}{\\partial\\mathbf{w}}E(\\mathbf{w}) =\n",
    " \\frac{\\partial}{\\partial\\mathbf{w}} \\frac{1}{2} \\sum_{n=1}^N (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w})^2\n",
    " $\n",
    "\n",
    "\n",
    " Poznámka: Gradient se dá ekvivalentně zapsat jako\n",
    " $ \\triangledown_{\\mathbf{w}} E(\\mathbf{w}) =\n",
    " \\frac{\\partial E (\\mathbf{w})}{\\partial \\mathbf{w}} =\n",
    "  \\begin{bmatrix} \\frac{\\partial E (\\mathbf{w})}{\\partial w_{0}} \\\\\n",
    "    \\frac{\\partial E (\\mathbf{w})}{\\partial w_{1}}\n",
    "    \\end{bmatrix}\n",
    "  $\n",
    "\n",
    "\n",
    "V následujícím kroku jsme si akorát konstantu vytkly před sumu, s tím že derivace sumy je suma derivací.\n",
    "\n",
    "$\n",
    "= \\frac{1}{2}  \\sum_{n=1}^N \\frac{\\partial}{\\partial\\mathbf{w}} (t_{n} - \\mathbf{\\hat x_{n}^T} \\mathbf{w})^2\n",
    "$\n",
    "\n",
    "Nyní naši objektivní funkci zderivujeme podle vektoru $ \\mathbf{w}$. Funkci derviuje klasicky jako složenou funkci,\n",
    "tj. druhou mocninu dám před funkci, zde se nám krásně vykrátí s naší konstantou a následně vynásobíme\n",
    "vnitřní složkou funkce\n",
    "\n",
    "\n",
    "$\n",
    "= \\sum_{n=1}^N (t_{n} - \\hat x_{n}^T \\mathbf{w}) \\frac{\\partial}{\\partial\\mathbf{w}}\n",
    "\\color{#f05454}{(t_{n} - \\hat x_{n}^T \\mathbf{w})}\n",
    "$\n",
    "\n",
    "\n",
    " Nyní nám zbýva zderivovat právě onu vnitřní složku funkce (červená část ). Když se na tuto část podíváme,\n",
    " zjistíme že první složka závorky  ($t_{n}$) je konstanta, tzn. ať už budeme derivovat podle čehokoliv,\n",
    " vždy to bude 0. Nás tedy bude zajímat druhá část závorky, kde je skalární součin vektoru, který budeme\n",
    " chtít derivovat podle vektoru $\\mathbf{w}$, což je vlastně parciální derivace podle\n",
    " jeho složek, tj. $w_{0}$ a $w_{1}$.\n",
    "\n",
    " Nyní si to více rozepíšeme. Potřebujeme tedy vypočítat derivaci druhé části červené závorky, což je:\n",
    "\n",
    "\n",
    " $\n",
    "  \\frac{\\partial}{\\partial \\mathbf{w}} \\mathbf{\\hat x}_{n}^T \\mathbf{w} =\n",
    "  $\n",
    "\n",
    "  $ =\\frac{\\partial}{\\partial \\mathbf{w}} \\begin{bmatrix}w_{0}x_{0} + \\space\n",
    "w_{1}x_{1}\n",
    "\\end{bmatrix}\n",
    " $\n",
    "\n",
    " Nyní máme rozepsaný skalární součin vektorů. Když ho zderivujeme podle $w_{0}$, dostaname $x_{0}$,\n",
    " když ho zderivujeme podle $w_{1}$, dostaneme $x_{1}$. To znamená, že derivace celé závorky je\n",
    " $\\mathbf{\\hat x}$, takže to tak můžeme přepsat i v červené části rovnice.\n",
    "\n",
    " $\n",
    "\\sum_{n=1}^N (t_{n} - \\hat x_{n}^T \\mathbf{w})\n",
    "\\color{#f05454}{\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "\n",
    "Aktuálně máme furt stejnou rovnici, která nám počítá gradient, akorát mírně upravenou. Nyní celou závorku\n",
    "vynásobíme vektorem $\\mathbf{\\hat x}$ (červeně), takže nám vzniknou dvě sumy. Dále, výraz položíme rovno\n",
    "0, protože nás samozřejmě zajímá, kde je gradient rovný 0, tzn. kde je minimum funkce.\n",
    "\n",
    " $\n",
    "\\sum_{n=1}^N t_{n}\n",
    "\\mathbf{\\hat x_{n}} - \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{ \\hat x}_{n}^T \\mathbf{w} = 0\n",
    "$\n",
    "\n",
    "Naším posledním větším krokem bude vytknout si $\\mathbf{w}$, což je vektor koeficientů $w_{0}$ a\n",
    "$w_{1}$. Nyní si první sumu si převedeme na pravou stranu rovnice.\n",
    "\n",
    "$\n",
    "\\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n} \\mathbf{w} = \\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}\n",
    "$\n",
    "\n",
    "\n",
    "Dále můžeme z levé strany rovnice oddělit $\\mathbf{w}$ od zbytku výrazu, protože $\\mathbf{w}$ nemá index sumy,\n",
    "tzn. na ní nezáleží.\n",
    "\n",
    "$\n",
    "\\color{#f05454}{( \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n})}  \\mathbf{w} = \\color{#59886b}{\\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "Nyní chcem dostat samotné $\\mathbf{w}$. To znamená, že celou rovnici musíme podělit červeným výrazem. Když si\n",
    "uvědomíme, že červený výraz je ve skutečnosti násobení sloupcového vektoru řádkovým, tzn. výsledek je matice\n",
    "2x2, tak zjistíme, že potřebujeme celou rovnici podělit maticí 2x2. Toho docílíme tak, že zleva k celé rovnici\n",
    "přínásobíme její inverzní matici. Na levé straně rovnice tedy zůstane samotné $\\mathbf{w}$, protože pokud\n",
    "matici vynásobíme její inverzní maticí, dostaneme jednotkovou matici.\n",
    "\n",
    "$\n",
    "\\mathbf{w} = \\color{#f05454}{( \\sum_{n=1}^N \\mathbf{\\hat x_{n}}  \\mathbf{\\hat x}^T_{n})^{-1}} \\color{#59886b}{\\sum_{n=1}^N t_{n}\\mathbf{\\hat x_{n}}}\n",
    "$\n",
    "\n",
    "A máme řešení! Pokud hodnoty vektoru $\\mathbf{w}$, tj. $w_{0}$ a $w_{1}$ nastavíme na hodnoty, které nám vrátí\n",
    "naše pravá strana rovnice, máme naše hledané parametry. Tento tvar ovšem není moc pěkný, protože pokud bychom to chtěli,\n",
    "implementovat, tak budeme muset pro červenou část rovnice  vytvořit for cyklus a vynásobit všechny složky vektoru $\\mathbf{\\hat x} $ s\n",
    "$\\mathbf{\\hat x^T} $ a následně vše sečíst. Obdobně bychom to museli udělat pro zelenou část rovnice. Nicméně my si můžeme\n",
    "vytvořit matici $\\mathbf{\\hat X} $, která bude obsahovat jako sloupce naše vektory $\\mathbf{\\hat x} $. Dále si také\n",
    "vytvoříme vektor našich hodnot datasetu, $\\mathbf{t} $.\n",
    "\n",
    "$\\mathbf{\\hat X} = [\\hat x_{1}, \\hat x_{2}, \\hat x_{3},..., \\hat x_{N}] $\n",
    "\n",
    "\n",
    "$\\mathbf{t} = [t_{1}, t_{2},  t_{3},..., t_{N}] $\n",
    "\n",
    "\n",
    "Červenou část rovnice nyní můžeme přepsat na součin matice $\\mathbf{X}$ s její  transponzicí, obdobně u zelené části.\n",
    "\n",
    "$\n",
    "\\mathbf{w} = \\color{#f05454}{(\\mathbf{\\hat X}  \\mathbf{\\hat X}^T)^{-1}} \\color{#59886b}{\\mathbf{\\hat X}\\mathbf{t}}\n",
    "$\n",
    "\n",
    "Nyní máme analytické řešení, které se skládá pouze z násobení maticemi, tzn. je lehce naprogramovatelné.\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lineární regrese\n",
    "Původ lineární regrese je založen na regresi k průměru.\n",
    "\n",
    "* *Jak to, že děti vysokých rodičů samy bývají vysoké, ale ne tak jako jejich rodiče?*\n",
    "\n",
    "#### Jednoduchá lineární regrese\n",
    "<img src=\"images/weight-height.jpg\" alt=\"weight-heigh\" width=\"250\" margin-bottom=\"20\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset obsahující záznamy o pohlaví-výška-váha\n",
    "Zdroj: https://www.kaggle.com/mustafaali96/weight-height\n",
    "\"\"\"\n",
    "\n",
    "wh_df = pd.read_csv('data/weight-height.csv')\n",
    "wh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Příklad jednoduché regresivní analýzy (pouze jeden regres)\n",
    "Z tohoto důvodu budeme zkoumat pouze muže a sloupec pohlaví můžeme ignorovat.\n",
    "Dále si převedeme hodnoty z datasetu na metrické jednotky, neboť jsou uvedeny v imperiálních hodnotách.\n",
    "\"\"\"\n",
    "\n",
    "# 1 palec = 2,54 cm\n",
    "height_constant = 2.54\n",
    "\n",
    "# 1 libra = 0,45359237 kg\n",
    "weight_constant = 0.4535923\n",
    "\n",
    "males_only_df = (wh_df[(wh_df.Gender == 'Male')]).drop('Gender',1) #\n",
    "males_only_df.Height *= height_constant\n",
    "males_only_df.Weight *= weight_constant\n",
    "males_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males_only_df.plot.scatter(x=\"Height\", y=\"Weight\", color='b', title='Height x Weight [Males only]', s=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ověření lineární korelační závislosti\n",
    "\n",
    "p - Pearsonův korelační koeficient měří sílu lineární závislosti mezi dvěma veličinami.\n",
    "\n",
    "OTÁZKA - Jakých hodnot může p nabývat?\n",
    "\"\"\"\n",
    "x = males_only_df.Height\n",
    "y = males_only_df.Weight\n",
    "p = stats.pearsonr(x, y)\n",
    "print(f\"Hodnota Pearsonova korelačního koeficientu: {p[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x.values.reshape((-1, 1)), y)\n",
    "# print(model.score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color = \"blue\", s=2)\n",
    "plt.plot(x, model.predict(x.values.reshape((-1, 1))), color = \"red\")\n",
    "plt.title(\"Male weight prediction\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color = \"blue\", s=2)\n",
    "plt.plot(x, model.predict(x.values.reshape((-1, 1))), color = \"red\")\n",
    "plt.title(\"Male weight prediction\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = input('Zadejte vaši výšku: ')\n",
    "weight_predict = model.predict(np.array(float(input_height)).reshape((-1, 1)))[0]\n",
    "print(f\"Predikovaná váha dle jednoduché lineární regresivní analýzy: {np.round(weight_predict, 2)}kg.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vícenásobná lineární regrese\n",
    "\n",
    "V reálném světě je výstup často ovlivněn více než jedním faktorem (regresem).\n",
    "\n",
    "$ y = f(x) = w_{0} + w_{1}x_{1} + w_{2}x_{2} + ... + w_{n}x_{n}  $\n",
    "<img src=\"images/fuel.png\" alt=\"fuel\" width=\"250\" margin-bottom=\"20\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset obsahuje záznamy kolik mil je daný automobil schopen ujet na jeden galon\n",
    "včetně dodatečných parametrů jako objem motoru, zrychlení etc.\n",
    "\"\"\"\n",
    "\n",
    "#MPG = Počet ujetých mil na jeden Galon (3,785 litru) -> Vyšší je lepší\n",
    "toLitres = lambda x : 235.214583 / x\n",
    "\n",
    "column_names = ['mpg', 'horsepower', 'weight', 'acceleration','displacement']\n",
    "\n",
    "cubic_inch_constant = 16.387064\n",
    "\n",
    "cars_df = pd.read_csv('data/auto-mpg.csv', usecols=column_names, na_values='?')\n",
    "cars_df.weight *= weight_constant\n",
    "cars_df.displacement *= cubic_inch_constant\n",
    "cars_df.dropna()\n",
    "\n",
    "cars_df.horsepower =  cars_df.horsepower.astype('float')\n",
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p1 = stats.pearsonr(cars_df['mpg'], cars_df['horsepower'])[0]\n",
    "p2 = stats.pearsonr(cars_df['mpg'], cars_df['weight'])[0]\n",
    "p3 = stats.pearsonr(cars_df['mpg'], cars_df['acceleration'])[0]\n",
    "p4 = stats.pearsonr(cars_df['mpg'], cars_df['displacement'])[0]\n",
    "\n",
    "print(f\"Míra lineární závislosti spotřeba x počet koní: {p1}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x hmotnost: {p2}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x zrychlení: {p3}.\")\n",
    "print(f\"Míra lineární závislosti spotřeba x zdvihový objem: {p4}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars_df.plot.scatter(x='horsepower', y='mpg', color='r', title='MPG x Horsepower')\n",
    "cars_df.plot.scatter(x='weight', y='mpg', color='b', title='MPG x Weight')\n",
    "cars_df.plot.scatter(x='acceleration', y='mpg', color='g', title='MPG x Acceleration')\n",
    "cars_df.plot.scatter(x='displacement', y='mpg', color='m', title='MPG x Zdvihový objem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LinearRegression()\n",
    "second_model_x = cars_df[['horsepower', 'acceleration', 'weight', 'displacement']]\n",
    "second_model_y = cars_df['mpg']\n",
    "\n",
    "# V datasetu jsou často výkonná auta u sebe, proto použijeme určitý pseudonáhodný pick\n",
    "seed = random.randint(0, 1000)\n",
    "\n",
    "second_model_x_train, second_model_x_test, \\\n",
    "second_model_y_train, second_model_y_test = train_test_split\\\n",
    "(second_model_x, second_model_y,test_size=0.25,random_state=seed)\n",
    "\n",
    "second_model.fit(second_model_x_train, second_model_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST přesnosti modelu\n",
    "\n",
    "accuracy = np.round(second_model.score(second_model_x_test, second_model_y_test), 4) * 100\n",
    "print(f'Přesnost modelu: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predikce spotřeby jiného staršího vozidla - použijeme Škodu 120\n",
    "# Zdroj: http://skodaps.wz.cz/S105-136_technicke_1.php\n",
    "\n",
    "# Nutné brát v potaz, že mnoho aut v datasetu jsou auta americká\n",
    "\n",
    "s120_horsepower = 53.0\n",
    "s120_acceleration = 20.0\n",
    "s120_weight = 890.0\n",
    "s120_displacement = 1147.0\n",
    "\n",
    "s120_stats = np.array([s120_horsepower,s120_acceleration, s120_weight, s120_displacement])\n",
    "result = second_model.predict(s120_stats.reshape(1, -1))[0]\n",
    "print(\"Predikovaná spotřeba vozu Škoda 120 pomocí vícenásobné lineární regresivní analýzy: {}l/100km.\".\\\n",
    "      format(np.round(toLitres(result), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomiální regrese\n",
    "\n",
    "Nyní si můžeme říct, že né všechny data se dají napasovat na lineární funkci, tzn. někdy je třeba\n",
    "aproximovat data polynomem. My se nyní naučíme aproximovat jakkoliv složitou funkci. Abychom\n",
    "tuto funkci ovšem mohli vytvořit, je nutné ji poskládat z jednodušších funkcí. Tyto funkce mohou\n",
    "být kupříkladu polynomy, obecně vzato to mohou být jakkékoliv nelineární funkce. Uvažujme například polynomy\n",
    "zobrazené na následujícím obrázku.\n",
    "![image info](images/polynomials.png)\n",
    "\n",
    "\n",
    "Když vytvoříme jejich linární kombinaci, může nám vzniknout například polynom zobrazený na následujícím obrázku.\n",
    "Vidíme tedy, že poměrně složitou funkci lze vytvořit složením funkcí jednodušších. Naším úkolem bude nyní\n",
    "hledat koeficienty polynomiální funkce tak, aby výsledná funkce co nejlépe aproximovala náš soubor dat.\n",
    "\n",
    "![image info](images/polynomial.png)\n",
    "\n",
    "\n",
    "Zde si můžeme opět vytvořit vektory $\\mathbf{\\hat x}$ a $\\mathbf{w}$ podobně, jako tomu bylo u lineární\n",
    "regrese. Nnyí ovšem tyto vektory nebudou dvojrozměrné, ale obecne K-rozměrné.\n",
    "\n",
    "$\n",
    "\\mathbf{\\hat x} =\n",
    "\\begin{bmatrix}1\\\\\n",
    "x\\\\\n",
    "x^2\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "x^K\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\mathbf{w} =\n",
    "\\begin{bmatrix}w_{0}\\\\\n",
    "w_{1}\\\\\n",
    "w_{2}\\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "w_{K}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Nyní úplně stejně jako při linární regresi, vytvoříme obecný předpis pro polynomiální funkci.\n",
    "\n",
    "$\n",
    "y = \\mathbf{\\hat x^T w} = w_{0} + w_{1}x + w_{2}x^2 + w_{3}x^3 + ... + w_{K}x^K\n",
    "$\n",
    "\n",
    "Pokud se podíváme pouze na první dva členy této funkce, zjistíme, že je to vlastně vzorec pro lineární regresi.\n",
    "Lineární regrese je tedy speciálním případem polynomiální regrese pro K=1.\n",
    "\n",
    "##### Polynomiální regrese příklad COVID-19\n",
    "<img src=\"images/covid.png\" alt=\"fuel\" width=\"250\" margin-bottom=\"20\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
    "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
    "\n",
    "import time\n",
    "order = 15\n",
    "\n",
    "for k in range(order):\n",
    "\n",
    "\n",
    "    mymodel = np.poly1d(np.polyfit(x, y, k))\n",
    "    plt.scatter(x, y, color='red', s=20)\n",
    "    myline = np.linspace(1, 22, 100)\n",
    "\n",
    "    plt.plot(myline, mymodel(myline))\n",
    "    plt.show()\n",
    "    time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predikce covid-19\n",
    "\n",
    "cols = ['country', 'cases', 'date', 'deaths', 'Cumulative_number_for_14_days_of_COVID-19_cases_per_100000']\n",
    "\n",
    "covid_csv = pd.read_csv('data/covid_dataset.csv', iterator=True, usecols=cols)\n",
    "\n",
    "covid_df = pd.concat([chunk[chunk['country'] == 'Czechia'] for chunk in covid_csv])\n",
    "\n",
    "covid_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every nth row and reverse dataset, so the newest values will be on the right side of plot\n",
    "import datetime as dt\n",
    "covid_df = covid_df.head(90).iloc[::-1]\n",
    "\n",
    "\n",
    "date = covid_df['date']\n",
    "cases = covid_df['cases']\n",
    "deaths = covid_df['deaths']\n",
    "cummulative = covid_df['Cumulative_number_for_14_days_of_COVID-19_cases_per_100000']\n",
    "\n",
    "\n",
    "# plt.xlabel('Covid-19 data in last 90 days', fontsize=15)\n",
    "plt.scatter(cummulative, deaths, s=10, color='red')\n",
    "\n",
    "\n",
    "plt.xlabel('cumulative cases for 14 days per 100k', fontsize=13)\n",
    "plt.ylabel('number of deaths', fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def find_best_order():\n",
    "    X_train_covid, X_test_covid, y_train_covid, y_test_covid = train_test_split(cummulative, deaths, test_size=0.2, random_state=0)\n",
    "    val = -1\n",
    "    order = 0\n",
    "    for k in range(1,10):\n",
    "        covid_model = np.poly1d(np.polyfit(X_train_covid, y_train_covid, k))\n",
    "        score = np.round(r2_score(y_test_covid, covid_model(X_test_covid)), 3)\n",
    "        print(\"actual best value {} and score {} and order {}\".format(val, score, k))\n",
    "        if score > val:\n",
    "            val = score\n",
    "            order = k\n",
    "\n",
    "    print(\"final order: {}\".format(order))\n",
    "    final_model = np.poly1d(np.polyfit(X_train_covid, y_train_covid, order))\n",
    "    print(\"R2 score is : {}\".format(r2_score(y_test_covid, covid_model(X_test_covid))))\n",
    "\n",
    "    return final_model\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(cummulative, deaths, s=10, color='red')\n",
    "plt.xlabel('cumulative cases for 14 days per 100k', fontsize=13)\n",
    "plt.ylabel('number of deaths', fontsize=13)\n",
    "\n",
    "covid_model = find_best_order()\n",
    "covid_line = np.linspace(0, 1700, 300)\n",
    "\n",
    "plt.plot(covid_line, covid_model(covid_line))\n",
    "plt.show()\n",
    "\n",
    "# print(\"R2 score is: {}\".format(np.round(r2_score(y_test_covid, covid_model(X_test_covid), 3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_input = 1700\n",
    "predicted_values = covid_model(predicted_input)\n",
    "\n",
    "print(\"Predikovany pocet umrti pri kumulativni nakaze {} lidi za 14 dni je {} umrti\".format(predicted_input, np.round(predicted_values, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Logistická regrese\n",
    "\n",
    "Logistická regrese je ač se to nemusí na první pohled zdát metodou klasifikace. Při regresi\n",
    "jsme měli nějaká vstupní data, a na jejichž základě jsme se snažili predikovat nějakou funkci, resp. číselnou hodnotu.\n",
    "Náš výstup byl tedy spojitý. Nyní se ovšem snažíme na základě vstupu predikovat nějakou\n",
    "třídu. Typicky nás nebude ovšem zajímat jenom do jaké třídy daný vstup spadá, nicméně i s jakou\n",
    "pravděpodobností. \n",
    "\n",
    "<img src=\"images/logistic.gif\" alt=\"drawing\" width=\"350\"/>\n",
    "\n",
    "\n",
    "\n",
    "Nnyí se pro zjednodušení omezíme pouze na jednu proměnnou, tzn. jeden faktor, dle kterého chceme náš vstup klasifikovat.\n",
    "Nyní budeme chtít, abychom náš vstup rozdělili do dvou tříd. To můžeme provést opět pomocí lineární přímky s předpisem\n",
    "\n",
    "$\n",
    "y = w_{0} + w_{1}x\n",
    "$\n",
    "\n",
    "Jenom hodnota toho výstupu by nám v případě klasifikace moc neřekla, tzn. rádi bychom ji převedli na pravděpodobnost.\n",
    "Z toho důvodu si zadefinujeme funkci, které při velmi malém vstupu bude vracet velmi malou pravděpodobnost, při hodnotě\n",
    "vstupu 0 bude vracet pravděpodobnost 50 %, a při narůstající kladné hodnotě X bude vracet stále větší pravděpodobnost.\n",
    "\n",
    "$\n",
    "g = \\frac{1}{1 + e^{\\color{#f05454}{-x}}}\n",
    "$\n",
    "\n",
    "Nyní nám stačí hodnotu vstupu X nahradit naší lineární funkcí.\n",
    "\n",
    "$\n",
    "g = \\frac{1}{1 + e^{\\color{#f05454}{-(w_{0} + w_{1}x)}}}\n",
    "$\n",
    "\n",
    "Tato funkce bude vypadat následovně.\n",
    "\n",
    "<img src=\"images/sigmoid.gif\" alt=\"drawing\" width=\"350\"/>\n",
    "\n",
    "\n",
    "Nyní máme podobný problém jako u regrese, hledáme parametry $w_{0}$ a $ w_{1}$ tak, aby chyba byla co nejmenší. Jenomže co je nyní\n",
    "chyba? V případě lineární regrese to byla suma všech čtverců, ale co tady? Pokud se znova podíváme na naši funkci $g(x)$, tak vidíme,\n",
    "že nám pro nějaký vstup vrací pravděpodobnost příslušnosti dané třídy, tzn. číselnou hodnotu neboli skalár. Mohli bychom tedy \n",
    "navrhnout, že vezme skutečnou hodnotu z našeho datasetu (což bude binární hodnota 1 nebo 0, tzn. patří do dané třídy / nepatří do dané třídy),\n",
    "odečteme od ní predikovanou hodnotu, kterou nám vrátí funkce $g(x)$ (což je pravděpodobnost, tzn. hodnota mezi 0 a 1), umocníme na\n",
    "druhou a posčítáme. Provedli bychom tedy opět metodu nejmenších čtverců. Nicméně to není vhodné, protože pokud se opět podíváme\n",
    "na naši funkci $g(x)$, tak zjistíme, že nemá jenom jedno globální minimum jak v případě lineární regrese, ale že má více lokálních\n",
    "minim, což je nepříjemné. Z toho důvodu použijeme křížovou entropii.\n",
    "\n",
    "Zadefinujeme se tedy novou funkci $e_{i}$\n",
    "\n",
    "\n",
    "$\n",
    "e_{i} = -log(g(x))$ pro y =  1\n",
    "\n",
    "\n",
    "$\n",
    "e_{i} = log(g(x))$ pro y =  0\n",
    "\n",
    "Pokud hodnota z datasetu (y) a hodnota z funkce $g(x)$ se shoduje, tak chyba je nulová. Čím více se však tyto parametry liší,\n",
    "tím více se chyba zvětšuje, až se limitně blíží k nekonečnu. \n",
    "\n",
    "\n",
    "Globální chybu si můžeme zapsat jako \n",
    "\n",
    "$\n",
    "E = \\sum_{i=1}^N e_{i}\n",
    "$\n",
    "\n",
    "Cílem je nalézt takové parametry $w_{0}$ a $ w_{1}$, aby daná chyba byla co nejmenší, což je dá řešit opět kupříkladu pomocí gradientího\n",
    "sestupu. Následující animace ukazuje převod linární funkce na funkci pravděpodobnosti. \n",
    "\n",
    "<img src=\"images/log_lin_to_sigmoid.gif\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "\n",
    "Pokud bychom chtěli náš problém generalizovat pro obecně N vstupů, mohli bychom postupovat obdobně jako u lineární regrese.\n",
    "\n",
    "$ \\mathbf{\\hat x}= \\begin{bmatrix}1 \\\\\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    ".\\\\\n",
    ".\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$ \\mathbf{w}= \\begin{bmatrix}w_{0} \\\\\n",
    "w_{1} \\\\\n",
    "w_{2} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "w_{n}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Obecný předpis pro funkci si nahradíme skalárním součinem vektorů proměnných a vah. Tento součin následně dosadíme do předpisu funkce vracející pravděpodobnost.\n",
    "$\n",
    "f(\\hat x) = = \\hat x^T w\n",
    "$\n",
    "\n",
    "$\n",
    "g(\\hat x) =  \\frac{1}{1 + e^{\\hat x^T w}}\n",
    "$\n",
    "\n",
    "#### Logistická regrese - Titanic\n",
    "<img src=\"images/titanic-meme.jpg\" alt=\"fuel\" width=\"350\" margin-bottom=\"20\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('data/titanic-dataset.csv')\n",
    "titanic_data = titanic_data.drop(columns = ['Name'])\n",
    "titanic_data['Fare'] = titanic_data['Fare'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived',data=titanic_data)\n",
    "plt.title('Titanic - přeživší [přežil x nepřežil]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Převod vybraných informací na pravdivostní hodnoty\n",
    "final_data = pd.get_dummies(titanic_data, columns =['Sex','Pclass'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.loc[:,final_data.columns != 'Survived']\n",
    "y = final_data.loc[:,final_data.columns == 'Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Vyrovnání vzorků (počet přeživších/zemřelých)\n",
    "smt = SMOTE(random_state=0)\n",
    "\n",
    "data_X,data_y=smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(max_iter=750)\n",
    "logistic_reg.fit(data_X, np.array(data_y).reshape(-1, 1))\n",
    "y_pred = logistic_reg.predict(X_test)\n",
    "print(f'Přesnost modelu logistické regrese: {np.round(logistic_reg.score(X_test, y_test) *100, 2)} %.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](images/CFmatrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(logistic_reg, X_test, y_test, cmap=plt.cm.Greens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, logistic_reg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logistic_reg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r-')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](images/ROC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Titanic - predikce přežití určitého pasažéra\n",
    "\n",
    "\n",
    "Cena lístků: Ticket Prices for the Titanic when she sailed on her maiden voyage \n",
    "in 1912: First Class Suite- £870 or $4,350. First Class Berth- £30 or $150.\n",
    "Second Class- £12 or $60.\n",
    "\n",
    "Na čem záviselo přežití: \n",
    "https://zoommagazin.iprima.cz/nejvetsi-katastrofy/prezili-byste-ztroskotani-titaniku-zname-vase-sance\n",
    "\"\"\"\n",
    "\n",
    "def predictSurvive(sex, age, p_class, parrents_childs, siblings, fare):\n",
    "    sex_male = True if sex == 'M' else False\n",
    "    if p_class == 1:\n",
    "        p_class_2 = False\n",
    "        p_class_3 = False\n",
    "    elif p_class == 2:\n",
    "        p_class_2 = True\n",
    "        p_class_3 = False\n",
    "    else:\n",
    "        p_class_2 = False\n",
    "        p_class_3 = True\n",
    "        \n",
    "\n",
    "    passsager = np.array([age, siblings, parrents_childs, fare, sex_male, p_class_2, p_class_3])\n",
    "    prediction = logistic_reg.predict(passsager.reshape(1, -1))\n",
    "    pst_died, pst_survived = logistic_reg.predict_proba(passsager.reshape(1, -1))[0]\n",
    "    if prediction:\n",
    "        print(\"Pravděpodobně by jste přežil s pravděpodobností {} %.\".format(np.round(pst_survived * 100, 2)))\n",
    "    else:\n",
    "        print(\"Pravděpodobně by jste zemřel s pravděpodobností {} %.\".format(np.round(pst_died * 100, 2)))\n",
    "\n",
    "sex = input('Zadejte pohlaví [M - muž, F - žena]: ')\n",
    "age = int(input('Zadejte věk: '))\n",
    "p_class = int(input('Zadejte třídu [1 - 3]: '))\n",
    "p_c_count = int(input('Zadejte počet rodičů/dětí na palubě: '))\n",
    "s_count = int(input('Zadejte počet sourozenců na palubě: '))\n",
    "fare = int(input('Zadejte cenu lístku [£]: '))\n",
    "\n",
    "predictSurvive(sex, age, p_class, p_c_count, s_count, fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression\n",
    "Metoda učení s učitelem používaná zejména na klasifikaci, ale možnost užít i na regresivní analýzu. Je použita technika, která kombinuje předpovědi z více algoritmů ML a vytváří tím přesnější předpověď.\n",
    "\n",
    "Pomocí rozhodovacích stromů lze vytvářet regresní modely formou stromových struktur. Regresní analýza pomocí rozhodovacích rozbije náš dataset na menší a menší podmnožiny.\n",
    "\n",
    "* Neparametrická metoda regrese (nejsou vyžadovány žádné zvláštní předpoklady ohledně rozdělení pravděpodobnosti náhodné veličiny)\n",
    "\n",
    "\n",
    "* Regresivní lesy x Klasifikační lesy\n",
    "\n",
    "##### Regresivní les\n",
    "* Je tvořen několika regresními stromy\n",
    "* Regresní les sestává z několika regresních stromů a výsledná regresní funkce je obvykle definována jako vážený průměr regresních funkcí jednotlivých stromů.\n",
    "<img src=\"images/randomForest.png\" alt=\"rf\" width=\"600\"/>\n",
    "\n",
    "##### Metoda random forrest\n",
    "* Pro metodu Random Forests se používají binární stromy typu CART (*Classification and Regression Tree*)\n",
    "* Použití: klasifikace, predikce, měření významnosti proměnných\n",
    "* Využít v každém rozhodovacím podstromu stejná data by nemělo smysl\n",
    "    * Využívají se bootstrapové výběry (náhodné výběry s opakováním) z trénovací množiny dat\n",
    "    * Některá data se do modelu dostanou vícekrát a některá se do modelu vůbec nemusejí dostat\n",
    "    * Pokud máme více prediktorů, je i jejich výběr pseudonáhodný\n",
    "    \n",
    "<img src=\"images/RFpicking.png\" alt=\"rfPick\" width=\"600\"/>\n",
    "\n",
    "<img src=\"images/rf.gif\" alt=\"rfGif\" width=\"600\"/>\n",
    "\n",
    "\n",
    "###### Typické využití\n",
    "<img src=\"images/usage.png\" alt=\"RFusage\" width=\"400\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Příklad - Dopočítání hodnot měny Bitcoin v minulosti dle omezených údajů\n",
    "\n",
    "<img src=\"images/btc.png\" alt=\"rfGif\" width=\"200\" align=\"left\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    - Příklad dopočítání chybějících hodnot měny Bitcoin\n",
    "    - Silně závisí na tom kolik máme dat, respektive vzdálenost vzorků a počtu stromů\n",
    "\"\"\"\n",
    "\n",
    "# Načtení zkoumaných dat\n",
    "column_names = ['Unix Timestamp', 'Date', 'Open']\n",
    "btc_df = pd.read_csv('data/btc-dataset.csv', usecols=column_names)\n",
    "plt.rcParams[\"figure.figsize\"] = (25,12)\n",
    "btc_df.plot.scatter(x=\"Unix Timestamp\", y=\"Open\", color='gold', title='Bitcoin value evolution');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Nastavení parametrů viz dokumentace\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\"\"\"\n",
    "\n",
    "days_per_sample = int(input(\"Zadejte vzdálenost vzorků ve dnech: \"))\n",
    "n_estimators = int(input(\"Zadejte počet stromů v lese: \"))\n",
    "\n",
    "\n",
    "X = (btc_df.iloc[::days_per_sample, 0].values).reshape(-1, 1)\n",
    "y = btc_df.iloc[::days_per_sample, 2].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "regressor = RandomForestRegressor(n_estimators, random_state = 42, min_samples_split=3)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_prediction = regressor.predict(X_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (25,12)\n",
    "plt.plot(btc_df['Unix Timestamp'], btc_df['Open'],color = 'gold')\n",
    "plt.plot(X_test, test_values_prediction,'ro',  color = 'blue')\n",
    "\n",
    "print(f\"Přesnost random forest modelu {np.round(regressor.score(X_test, y_test) * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda podpůrných vektorů\n",
    "\n",
    "Opět metoda učení s učitelem, která se používá zejména v klasifikaci, ale může nalézt využití i v regresivní analýze.\n",
    "\n",
    "SVM hledá nadrovinu, která v prostoru příznaků optimálně rozděluje trénovací data.\n",
    "\n",
    "* *Optimální nadrovina* - je taková, že body leží v opačných poloprostorech a hodnota minima vzdáleností bodů od roviny je co největší. Jinými slovy, okolo nadroviny je na obě strany co nejširší pruh bez bodů. \n",
    "\n",
    "\n",
    "Regrese dat založená na SVM využívá necitlivou ztrátovou funkci - pokud je chyba menší než $\\epsilon$, není to považováno za chybu.\n",
    "\n",
    "* Nová metoda v oblasti strojového  učení\n",
    "* Neparametrická metoda regrese\n",
    "* Alterinativa pro neuronové sítě\n",
    "* Správná funkce SVM z velké části záleží na vhodné volbě jádrové funkce\n",
    "* Jádrová transformace - umožňuje převést původně lineárně neseparovatelnou úlohu na úlohu lineárně separovatelnou, na kterou lze dále aplikovat optimalizační algoritmus pro nalezení rozdělující nadroviny (typicky se převání na vyšší dimenze)\n",
    "\n",
    "<img src=\"images/SVRtransform.png\" alt=\"SVRtranform\" width=\"600\"/>\n",
    "\n",
    "\n",
    "\n",
    "Bližší info pro zájemce : [ČVUT](http://buon.fjfi.cvut.cz:5002/FTTF/Marianska/11/Presentace/OdstrcilM.pdf), [PPT prezentace](external/SVM.ppt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predikce vývoje měny Bitcoin\n",
    "* Bohužel vývoj nelze s určitostí predikovat\n",
    "* Lze pouze hledat určitý vztah mezi vývojem měny a hodnotami v historii\n",
    "* Příklad slouží pouze pro účely demonstrace použití SVM, investice na vlastní riziko\n",
    "\n",
    "\n",
    "<img src=\"images/moneySad.jpg\" alt=\"moneySad\" width=\"200\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Epsilon-Support Vector Regression\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "    \n",
    "Parametry:\n",
    "    C - penalizace vzdálených pozorování\n",
    "    epsilon - rozptyl dat\n",
    "    kernel - Volba jádra\n",
    "\"\"\"\n",
    "\n",
    "PREDICT_SIZE = int(input('Zadejte požadovanou délku predikce [v dnech]: '))\n",
    "HISTORY_LEN = int(input('Zadejte požadovanou délku uvažované historie kterou chcete při predikci uvažovat [v dnech]: '))\n",
    "\n",
    "# Příprava a úprava dat\n",
    "df = pd.read_csv('data/btc-dataset.csv', usecols=['Open']).head(HISTORY_LEN)\n",
    "prediction_days = PREDICT_SIZE\n",
    "df['Prediction'] = df['Open'].shift(-prediction_days)\n",
    "yvm = np.array(df.drop(['Prediction'],1))\n",
    "yvm = yvm[:len(df)-prediction_days]\n",
    "Xvm = np.array(df['Prediction'])  \n",
    "Xvm = Xvm[:-prediction_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = random.randint(0, 1000)\n",
    "\n",
    "#xvm_train, xvm_test, yvm_train, yvm_test = train_test_split(Xvm, yvm, test_size=0.15, random_state=seed)\n",
    "xvm_train = Xvm\n",
    "yvm_train = yvm\n",
    "prediction_days_array = np.array(df.drop(['Prediction'],1))\n",
    "prediction_days_array = prediction_days_array[:prediction_days]\n",
    "svr_rbf = SVR(kernel='rbf',C=1000,epsilon = 0.001)\n",
    "svr_rbf.fit(xvm_train.reshape(-1,1), yvm_train)\n",
    "\n",
    "#print(f\"Vectorová regrese přenost modelu: {np.round(svr_rbf.score(xvm_test, yvm_test),4) * 100} %.\", )\n",
    "\n",
    "\n",
    "svm_prediction = svr_rbf.predict(prediction_days_array)\n",
    "\n",
    "plt.plot(range(1, PREDICT_SIZE + 1), svm_prediction ,color = 'green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}